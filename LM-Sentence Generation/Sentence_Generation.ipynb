{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sentence Generation\n"
      ],
      "metadata": {
        "id": "CKwpKQcjVhUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and Initializations"
      ],
      "metadata": {
        "id": "5QiEDIyAW1j-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oA1Spx6TM6CE"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import gutenberg\n",
        "nltk.download('punkt', quiet = True)\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "nltk.download('gutenberg', quiet = True)\n",
        "from nltk.util import ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whc9S75Xs9xo",
        "outputId": "7832deac-1ffc-4c0d-e0cf-aa8e4408f5eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "austen-emma.txt\n",
            "austen-persuasion.txt\n",
            "austen-sense.txt\n",
            "bible-kjv.txt\n",
            "blake-poems.txt\n",
            "bryant-stories.txt\n",
            "burgess-busterbrown.txt\n",
            "carroll-alice.txt\n",
            "chesterton-ball.txt\n",
            "chesterton-brown.txt\n",
            "chesterton-thursday.txt\n",
            "edgeworth-parents.txt\n",
            "melville-moby_dick.txt\n",
            "milton-paradise.txt\n",
            "shakespeare-caesar.txt\n",
            "shakespeare-hamlet.txt\n",
            "shakespeare-macbeth.txt\n",
            "whitman-leaves.txt\n"
          ]
        }
      ],
      "source": [
        "# List all the available book names in the Gutenberg corpus\n",
        "gutenberg_books = gutenberg.fileids()\n",
        "\n",
        "# Print the list of book names\n",
        "for book in gutenberg_books:\n",
        "    print(book)\n",
        "\n",
        "# Define the list of book titles\n",
        "book_titles = [\n",
        "    \"austen-emma.txt\",\n",
        "    \"austen-sense.txt\",\n",
        "    \"bryant-stories.txt\",\n",
        "    \"burgess-busterbrown.txt\",\n",
        "    \"carroll-alice.txt\",\n",
        "    \"chesterton-brown.txt\",\n",
        "    \"chesterton-thursday.txt\",\n",
        "    \"edgeworth-parents.txt\",\n",
        "    \"melville-moby_dick.txt\",\n",
        "    \"milton-paradise.txt\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wxeFsNYieKM"
      },
      "source": [
        "## Create Trie Structure\n",
        "\n",
        "This code defines a Trie data structure and functions to create and search within it. It processes a list of texts, tokenizes them into sentences and words, removes punctuation, adds start and stop tokens, then generates and updates the Trie with n-grams of specified length. Finally, it allows searching for counts of specific n-grams within the created Trie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "up7fep_2wf3x"
      },
      "outputs": [],
      "source": [
        "class TrieNode:\n",
        "    def __init__(self):\n",
        "        self.children = {}\n",
        "        self.count = 0\n",
        "\n",
        "def update_trie(node, n_gram):\n",
        "    current_node = node\n",
        "    for word in n_gram:\n",
        "        if word not in current_node.children:\n",
        "            current_node.children[word] = TrieNode()\n",
        "        current_node = current_node.children[word]\n",
        "    current_node.count += 1\n",
        "\n",
        "def create_trie(text_list, depth):\n",
        "  # Initialize root node for unigrams\n",
        "  root_node = TrieNode()\n",
        "\n",
        "  # Processing each text\n",
        "  for text in text_list:\n",
        "      # Tokenize the book into sentences\n",
        "      sentences = sent_tokenize(text)\n",
        "\n",
        "      # Process each sentence\n",
        "      for sentence in sentences:\n",
        "          # Tokenize the sentence into words\n",
        "          words = word_tokenize(sentence)\n",
        "\n",
        "          # Removing punctuation from words\n",
        "          words = [word.lower() for word in words if word.isalnum()]\n",
        "\n",
        "          # Add start and stop tokens\n",
        "          words = ['<s>'] + words + ['</s>']\n",
        "\n",
        "          # Generate and update trie for each n-gram\n",
        "          for n in range(1, depth+1):\n",
        "              n_grams = list(ngrams(words, n))\n",
        "              for gram in n_grams:\n",
        "                  update_trie(root_node, gram)\n",
        "\n",
        "  return root_node\n",
        "\n",
        "# Helper functions to better understand the structure\n",
        "def print_trie(node, depth=0, max_depth=3, prefix=[]):\n",
        "    if depth > max_depth:\n",
        "        return\n",
        "    if node.count > 0:\n",
        "        print(' '.join(prefix), node.count)\n",
        "    for word, child_node in node.children.items():\n",
        "        print_trie(child_node, depth + 1, max_depth, prefix + [word])\n",
        "\n",
        "def search_trie(node, key):\n",
        "    current_node = node\n",
        "    for word in key:\n",
        "        if word not in current_node.children:\n",
        "            return 0\n",
        "        current_node = current_node.children[word]\n",
        "    return current_node.count if current_node else 0\n",
        "\n",
        "# Choose the n in n-grams\n",
        "N_GRAM_LENGTH = 6\n",
        "\n",
        "book_texts = [gutenberg.raw(book_title) for book_title in book_titles]\n",
        "\n",
        "root_node = create_trie(book_texts, N_GRAM_LENGTH)\n",
        "\n",
        "# print(\"N-gram Trie Structure (up to depth 3):\")\n",
        "#print_trie(root_node, max_depth=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3LKtdR7ogvb",
        "outputId": "8938e2ae-cb2c-48f4-9f0b-10ee7b558880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key frequency is 149\n"
          ]
        }
      ],
      "source": [
        "# How to search for a key:\n",
        "count = search_trie(root_node, [\"the\", \"sun\"])\n",
        "print(f\"Key frequency is {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slKMK7Tvatxp"
      },
      "source": [
        "## Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = list(root_node.children.keys()) # Vocabulary is the unigrams\n",
        "vocabulary.remove(\"<s>\")\n",
        "vocabulary.remove(\"</s>\") #\n",
        "# Display the size of the general vocabulary\n",
        "print(f\"Size of vocabulary: {len(vocabulary)} words\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fur-7EOyNCVb",
        "outputId": "9fdc8618-9fea-49db-cfae-b7541a9680b5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of vocabulary: 27460 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHFc9HL3iY32"
      },
      "source": [
        "## Generate Sentences\n",
        "This code generates sentences using an n-gram model based on a Trie data structure. It starts by randomly generating starting n-grams of specified lengths from the Trie, then iteratively generates subsequent words based on the previous n-gram. The generated sentences are then beautified by capitalizing the first letter and 'I', and adding periods. Finally, it prints out sentences for different n-gram lengths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWYXN6Z2JmvW",
        "outputId": "f2c9d549-a0fb-4fed-8f75-94bc2412fb51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentences using 2-grams:\n",
            "1. The only way to move him was to depend.\n",
            "2. His situation is an evil but you must give me a living.\n",
            "3. The everlasting whip cord I declare.\n",
            "4. He did not even move a hair and syme could come close enough to a whale before any pitchpoling comes into play.\n",
            "5. Papa laughed.\n",
            "\n",
            "Sentences using 3-grams:\n",
            "1. Churchill after being disliked at least years was now spoken of with compassionate allowances.\n",
            "2. Repeated the doctor with a start but what on earth can he agent he thought mahanaim where he adam at the news with chilling gripe of sorrow stood that.\n",
            "3. And where do you think he was in rashness leads not on.\n",
            "4. After the farmer was dead the hosts of light.\n",
            "5. My dear miss gregory said syme gently there are many kinds of sincerity and insincerity.\n",
            "\n",
            "Sentences using 4-grams:\n",
            "1. Who will none shall from me withhold thy offered good distance from those she wants to be with but one can not comprehend a young being under such restraint.\n",
            "2. Doated introductions jonah and the whale.\n",
            "3. Here comes your beau nancy my cousin said day when she saw him crossing the street to the house.\n",
            "4. No use sterning all then but as I was groping at innocent he went on eating his dinner in silence.\n",
            "5. These were the ladies whom emma found herself very frequently able to collect and happy was she for her father sake in the power though as far as she.\n",
            "\n",
            "Sentences using 5-grams:\n",
            "1. Alice had been looking over his shoulder with some curiosity.\n",
            "2. Had he anything to tell the prince.\n",
            "3. Woodhouse saw the letter and he says he never saw such a handsome letter in his life.\n",
            "4. In places you see it bubblingly up like old wine worked anew.\n",
            "5. Is there anything in our house can be of service to her.\n",
            "\n",
            "Sentences using 6-grams:\n",
            "1. Grant when he heard of all this endeavoured to discover what could have offended his neighbour but all explanation was prevented by the obstinate silence of oakly.\n",
            "2. So almost every hours when the watches of the night were set and the band on deck sentinelled the slumbers of the band below and when if a rope.\n",
            "3. Ah here comes your champagne.\n",
            "4. Unjust brittle fishiest grosser and weighs and exhibited that stump to an incredulous world.\n",
            "5. Then yours was a really good school said the mock turtle in a deep hollow tone down both of you and do speak a word till I finished.\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def generate_next_word(node, node_name, words, smoothing_words = None, creativity = 0.000001):\n",
        "    # Base case\n",
        "    if len(words) == 0:\n",
        "        if not node.children: # If the node doesn't have children\n",
        "            return None\n",
        "\n",
        "        children = node.children\n",
        "        # Extract counts and words\n",
        "        counts = [child.count for child in children.values()]\n",
        "        possible_words = list(children.keys())\n",
        "\n",
        "        # Add the smoothing if it exists\n",
        "        if smoothing_words:\n",
        "          possible_words.extend(smoothing_words)\n",
        "          counts.extend([creativity] * len(smoothing_words))\n",
        "\n",
        "        # Choose randomly based on the weight of counts\n",
        "        next_word = random.choices(possible_words, weights=counts)[0]\n",
        "        #print(\"Next word chosen \", next_word)\n",
        "\n",
        "        return next_word\n",
        "\n",
        "    word = words[0]\n",
        "    #print(\"Node: \", node_name, \"\\nLooking for: \", word)\n",
        "\n",
        "    if word not in node.children.keys():\n",
        "      #print(\"Key not found\")\n",
        "      return None\n",
        "    next_node = node.children[word]\n",
        "    next_word = generate_next_word(next_node, word, words[1:], smoothing_words)\n",
        "    return next_word\n",
        "\n",
        "def generate_starting_ngram(node, length, max_attempts=3, vocabulary = vocabulary):\n",
        "    ngram = [\"<s>\"]\n",
        "    attempts = 0\n",
        "\n",
        "    while len(ngram) < length:\n",
        "        next_word = generate_next_word(node, \"root\", ngram)\n",
        "        if next_word is not None and next_word != \"</s>\":\n",
        "            ngram.append(next_word)\n",
        "            attempts = 0  # Reset attempts if a word is successfully added\n",
        "        else:\n",
        "            placeholder = random.choice(vocabulary)  # Choose a random word from the vocabulary list\n",
        "            ngram.append(placeholder)\n",
        "            attempts += 1\n",
        "            if attempts >= max_attempts:\n",
        "                break  # Break out of the loop if maximum attempts reached without finding a valid next word\n",
        "\n",
        "    return ngram[:length]  # Ensure the n-gram is of the specified length\n",
        "\n",
        "\n",
        "def generate_sentences(node, n, max_length=30, num_sentences=5, vocabulary = vocabulary):\n",
        "    sentences = []\n",
        "    while len(sentences) < num_sentences:\n",
        "        sentence = generate_starting_ngram(node, n)\n",
        "        while len(sentence) < max_length:\n",
        "            for i in range(len(sentence) - 1):\n",
        "                words = sentence[-n + i - 1:]\n",
        "                next_word = generate_next_word(node, \"root\", words, smoothing_words = vocabulary)\n",
        "                if next_word is not None:\n",
        "                    break\n",
        "            if next_word is None:\n",
        "              next_word = random.choice(vocabulary) if sentence[-1] == \"and\" else \"and\"\n",
        "            if next_word == \"</s>\":\n",
        "                break\n",
        "            sentence.append(next_word)\n",
        "        sentence_str = ' '.join(sentence[1:])\n",
        "        # Check if the sentence is unique\n",
        "        if sentence_str not in sentences:\n",
        "            sentences.append(sentence_str)\n",
        "    return sentences\n",
        "\n",
        "def beutify_sentences(sentence_list):\n",
        "  # Capitalize the first letter and I and add a period\n",
        "  sentences = [sentence.capitalize().replace(\" i \", \" I \") + '.' for sentence in sentence_list]\n",
        "  return sentences\n",
        "\n",
        "def generate_and_print_sentences(root_node, n, num_sentences=5, vocabulary = vocabulary):\n",
        "    sentences = generate_sentences(root_node, n, num_sentences=num_sentences, vocabulary = vocabulary)\n",
        "    sentences = beutify_sentences(sentences)\n",
        "    print(f\"\\nSentences using {n}-grams:\")\n",
        "    for i, sentence in enumerate(sentences, 1):\n",
        "        print(f\"{i}. {sentence}\")\n",
        "\n",
        "# Generate and print sentences for different n-gram lengths\n",
        "generate_and_print_sentences(root_node, 2)\n",
        "generate_and_print_sentences(root_node, 3)\n",
        "generate_and_print_sentences(root_node, 4)\n",
        "generate_and_print_sentences(root_node, 5)\n",
        "generate_and_print_sentences(root_node, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2iy880sc88B"
      },
      "source": [
        "## Text-to-Image Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTDCZsJWdApA",
        "outputId": "88cae012-504d-4702-e7b9-ffe9b29258ec",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentences using 2-grams:\n",
            "1. Words have suddenly lost their meaning and the air is too dense.\n",
            "2. Pure white feathers decorate the creature sharp like swords ready to slice the flesh with the lightest touch.\n",
            "3. And so the battle continues a dragon and a knight until one prevails.\n",
            "4. The knight picks up the spear.\n",
            "5. They feel like bottomless pits like the absense of eyes and everything else they pierce through shiny armors and feed the emptiness in human souls until there nothing left.\n",
            "\n",
            "Sentences using 3-grams:\n",
            "1. Paper dragons dislike words.\n",
            "2. It ready to attack.\n",
            "3. I am a knight the knight says.\n",
            "4. The knight stands opposite of the dragon.\n",
            "5. On the now and a knight until one prevails.\n",
            "\n",
            "Sentences using 4-grams:\n",
            "1. Their bodies break under the dragon legs as it arches its body backwards.\n",
            "2. The only path the knight can follow lies straight ahead.\n",
            "3. Still it seems like the whole battlefield is tingling with anticipation waiting to see who will make the first the dragon charges violently forward tearing everything in its way.\n",
            "4. And so the battle continues a dragon and a knight until one prevails.\n",
            "5. I am a knight the knight thinks.\n",
            "\n",
            "Sentences using 5-grams:\n",
            "1. Lost souls cursed to wander in touch.\n",
            "2. The knight stands opposite of the dragon.\n",
            "3. Their bodies break under the dragon legs as it arches its body backwards.\n",
            "4. The only path the knight can follow lies straight ahead.\n",
            "5. It opens its huge mouth and defeaning silence comes out.\n",
            "\n",
            "Sentences using 6-grams:\n",
            "1. Paper dragons dislike words thrasher and as it arches its body backwards.\n",
            "2. They feel like bottomless pits like the absense of eyes and everything else they pierce through shiny armors and feed the emptiness in human souls until there nothing left.\n",
            "3. The sight is mesmerizing but the knight knows better than to look for this dragon is special.\n",
            "4. The only path the knight can follow lies straight ahead.\n",
            "5. It ready to attack jointure and pointy spear points at the beast direction.\n"
          ]
        }
      ],
      "source": [
        "# @title Generate Prompts { vertical-output: true }\n",
        "story = \"The knight stands opposite of the Dragon. It is a ferocious beast; Fifty times the size of a grown man, its body constantly moving, contorting in strange and unnatural ways. Pure white feathers decorate the creature, sharp like double-edged swords, ready to slice the flesh with the lightest touch. They move with the wind, each one dancing to its own rhythm, making the Dragon feel even more alive. The sight is mesmerizing, but the knight knows better than to look, for this Dragon is special. Its deadliest weapon isn't its needle-like teeth, or its sharp claws, but its black, abysmall eyes. They feel like bottomless pits, like the absense of eyes and everything else, they pierce through shiny armors and feed the emptiness in human souls until there's nothing left. On the ground, the bodies of better knights are scattered like flowers. Some alive, some dead, and some in-between. Lost souls, cursed to wander in places unknown. Their bodies break under the Dragon's legs as it arches its body backwards. It opens its huge mouth, and defeaning silence comes out. It's ready to attack.  \\\"I am a knight\\\", the knight thinks.   The knight's plain brown horse neighs in disagreement as they move into position. A pointy spear points at the beast's direction. Words have suddenly lost their meaning, and the air is too dense. Still, it seems like the whole battlefield is tingling with anticipation, waiting to see who will make the first mo- The Dragon charges violently forward, tearing everything in its way apart, its claws scratching the ground, leaving deep scars. It's wrong, very wrong, because dragons aren't supposed to move that fast, turn something into nothing this quickly. The world has been replaced by a void, and the void is being replaced by [     ]. The only path the knight can follow lies straight ahead.  \\\"I am a knight\\\", the knight says.  The two imbalanced bodies collide; for a moment, everything is still. A horse's scream breaks the silence, and a knight's one joins it. But the greatest scream is the one that never gets heard. The Dragon feels the spear leaving its body, just above the shoulder, feels the wound opening, allowing for the inside to become outside. Surprisingly, it's not blood that comes out, but ink, black as a night without stars. It stains the rich white feathers, and it's beautiful in a way, because it paints letters.   \\\"I am a knight\\\", the knight writes.  Paper dragons dislike words. It's angry now, preparing to attack again. The knight picks up the spear. And so the battle continues, a Dragon and a knight, until one prevails.\" # @param {type:\"string\"}\n",
        "N_GRAM_LENGTH = 6\n",
        "\n",
        "texts = [story]\n",
        "\n",
        "story_root_node = create_trie(texts, N_GRAM_LENGTH)\n",
        "story_vocabulary = list(story_root_node.children.keys()) # Vocabulary is the unigrams\n",
        "story_vocabulary.remove(\"<s>\")\n",
        "story_vocabulary.remove(\"</s>\")\n",
        "\n",
        "generate_and_print_sentences(story_root_node, 2, vocabulary = story_vocabulary)\n",
        "generate_and_print_sentences(story_root_node, 3, vocabulary = story_vocabulary)\n",
        "generate_and_print_sentences(story_root_node, 4, vocabulary = story_vocabulary)\n",
        "generate_and_print_sentences(story_root_node, 5, vocabulary = story_vocabulary)\n",
        "generate_and_print_sentences(story_root_node, 6, vocabulary = story_vocabulary)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}